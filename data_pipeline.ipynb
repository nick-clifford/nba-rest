{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nick Clifford\n",
    "- April 30, 2020\n",
    "- SYS 6016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final: Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 20\n",
    "\n",
    "datadir = '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in team data\n",
    "bask = pd.read_csv(datadir + '/updated_bask_data2.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove playoff season games, reset index\n",
    "bask = bask[pd.isnull(bask.playoff)]\n",
    "bask.index = range(len(bask))\n",
    "\n",
    "# drop playoff, elo_pre, and score columns\n",
    "bask = bask.drop(['playoff', 'elo1_pre', 'elo2_pre', 'score1', 'score2'], axis=1)\n",
    "\n",
    "# convert home/away team cols to a binary col for home for the team of interest\n",
    "bask['home'] = pd.Series(np.where(bask['team1..Home.'] == bask.team_of_interest, 1, 0))\n",
    "\n",
    "# rename team_of_interest to team\n",
    "bask = bask.rename({'team_of_interest':'team'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-star Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all-star data\n",
    "stars = pd.read_excel(datadir + '/All Star List.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn every 4 columns into df, remove NaN values from each, rename columns to same heading, add a date column for year of all-star game\n",
    "df16 = stars.iloc[:-2,:4].rename({'2015 2016 All Stars': 'player', 'Team':'team', 'Starter?':'starter', 'Age':'age'}, axis=1)\n",
    "df16['season'] = 2016\n",
    "\n",
    "df17 = stars.iloc[:-2,4:8].rename({'2016 2017 All Stars': 'player', 'Team.1':'team', 'Starter?.1':'starter', 'Age.1':'age'}, axis=1)\n",
    "df17['season'] = 2017\n",
    "\n",
    "df18 = stars.iloc[:-3,8:12].rename({'2017 2018 All Stars': 'player', 'Team.2':'team', 'Starter?.2':'starter', 'Age.2':'age'}, axis=1)\n",
    "df18['season'] = 2018\n",
    "\n",
    "df19 = stars.iloc[:,12:16].rename({'2018 2019 All Stars': 'player', 'Team.3':'team', 'Starter? ':'starter', 'Age.3':'age'}, axis=1)\n",
    "df19['season'] = 2019\n",
    "\n",
    "df20 = stars.iloc[:-2,16:20].rename({'2019 2020 All Stars': 'player', 'Team.4':'team', 'Starter?.3':'starter', 'Age.4':'age'}, axis=1)\n",
    "df20['season'] = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat table into long format\n",
    "stars = pd.concat([df16, df17, df18, df19, df20])\n",
    "#stars['season'] = pd.to_datetime(stars.season, format='%Y')\n",
    "\n",
    "# fix misspelled player names and lowercase everything\n",
    "stars['player'] = stars.player.str.strip()\n",
    "stars.player.replace('Bradly Beal', 'Bradley Beal', inplace=True)\n",
    "stars.player.replace('Ressell Westbrook', 'Russell Westbrook', inplace=True)\n",
    "stars.player.replace('Ressell Westbrook', 'Russell Westbrook', inplace=True)\n",
    "stars['player'] = stars.player.str.lower()\n",
    "\n",
    "# add birthday column as opposed to using age as feature \n",
    "stars['born'] = stars.season - stars.age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injury Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in injury data\n",
    "miss = pd.read_csv(datadir + '/abscences.csv', index_col=0, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all player names\n",
    "miss['player'] = miss.player.str.lower()\n",
    "\n",
    "\n",
    "team_names = {'76ers':'PHI', 'Blazers':'POR', 'Bucks':'MIL', 'Bulls':'CHI', \n",
    "              'Cavaliers':'CLE', 'Celtics':'BOS', 'Clippers':'LAC',  'Grizzlies':'MEM', \n",
    "              'Hawks':'ATL', 'Heat':'MIA', 'Hornets':'CHO','Jazz':'UTA', 'Kings':'SAC', \n",
    "              'Knicks':'NYK', 'Lakers':'LAL', 'Magic':'ORL', 'Mavericks':'DAL', 'Nets':'BRK',\n",
    "              'Nuggets':'DEN', 'Pacers':'IND', 'Pelicans':'NOP', 'Pistons':'DET', \n",
    "              'Raptors':'TOR', 'Rockets':'HOU', 'Spurs':'SAS', 'Suns':'PHO', 'Thunder':'OKC', \n",
    "              'Timberwolves':'MIN', 'Warriors':'GSW', 'Wizards':'WAS'}\n",
    "\n",
    "# remove rows where team is NaN or 'Bullets'\n",
    "miss = miss[pd.notnull(miss.team)]\n",
    "miss = miss[miss.team != 'Bullets'] \n",
    "\n",
    "# replace team name with abbreviation to match other tables\n",
    "miss['team'] = miss.team.replace(team_names)\n",
    "\n",
    "# add a season column according date of the action\n",
    "# regular_season date dictionary: {'season year': ['startdate','endate']}\n",
    "reg_dates = {'2016': [pd.to_datetime('2015-10-27'), pd.to_datetime('2016-04-13')],\n",
    "             '2017':[pd.to_datetime('2016-10-25'),pd.to_datetime('2017-04-12')],\n",
    "             '2018':[pd.to_datetime('2017-10-17'),pd.to_datetime('2018-04-11')],\n",
    "             '2019':[pd.to_datetime('2018-10-16'),pd.to_datetime('2019-04-13')],\n",
    "             '2020':[pd.to_datetime('2019-10-22')]}\n",
    "\n",
    "# new season starts on beginning of the regular season\n",
    "miss['season'] = np.where(miss.date < reg_dates['2020'][0], 2019, 2020)\n",
    "miss['season'] = np.where(miss.date < reg_dates['2019'][0], 2018, miss['season'])\n",
    "miss['season'] = np.where(miss.date < reg_dates['2018'][0], 2017, miss['season'])\n",
    "miss['season'] = np.where(miss.date < reg_dates['2017'][0], 2016, miss['season'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine team & player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we input an all-start name and recover their nba schedule from seasons 2015 to 2020. Then we find which days the player was moved to and from the active roster. We create features for games which we know the players are absent (injury, suspension, etc.) and labels for the games that players DNP for rest (located in injury notes). The result is a individual player datatable, with team/player features as columns and game observation rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(player_name):\n",
    "    \"\"\"Given a player name, output a combined table of player and table data \n",
    "    including fields for injury/suspension and rest labels\"\"\"\n",
    "    \n",
    "    player_name = player_name.lower()\n",
    "    \n",
    "    # get the birthday of the player \n",
    "    born = stars.groupby('player').get_group(player_name).born.value_counts().index[0]\n",
    "    \n",
    "    # subset injury data to that of the player\n",
    "    if player_name == 'john wall':\n",
    "        df_miss = miss.query('player == \"john wall (hildred)\"')\n",
    "    elif player_name == 'domantas sabonis':\n",
    "        df_miss = miss.query('player == \"domantas sabonis / domas sabonis\"')\n",
    "    elif player_name == 'bam adebayo':\n",
    "        df_miss = miss.query('player == \"edrice adebayo / bam adebayo\"')\n",
    "                \n",
    "    else:\n",
    "        df_miss = miss.query('player == @player_name')\n",
    "\n",
    "    # get combination of team and the season year for the player\n",
    "    player_seasons = df_miss.groupby(['season', 'team']).size().index.to_list()\n",
    "    \n",
    "    # get list of dates games that player played according to the team they played with that season    \n",
    "    df_bask = bask.set_index(['season','team']).loc[player_seasons].reset_index()\n",
    "    game_dates = df_bask.date.to_list()\n",
    "    \n",
    "    # acquired dates\n",
    "    doA = df_miss.query('action == \"acquired\"')['date']\n",
    "    # relinquished dates\n",
    "    doR = df_miss.query('action == \"relinquished\"')['date']\n",
    "\n",
    "    # find the dates that the player rested and did not play\n",
    "    rest_dates = df_miss[(df_miss.notes.str.contains('rest ')) & (df_miss.action == 'relinquished')]['date'].to_list()\n",
    "    rest_array = np.isin(game_dates, rest_dates).astype(int)\n",
    "    \n",
    "    reg_dates = {'2016': [pd.to_datetime('2015-10-27'), pd.to_datetime('2016-04-13')],\n",
    "             '2017':[pd.to_datetime('2016-10-25'),pd.to_datetime('2017-04-12')],\n",
    "             '2018':[pd.to_datetime('2017-10-17'),pd.to_datetime('2018-04-11')],\n",
    "             '2019':[pd.to_datetime('2018-10-16'),pd.to_datetime('2019-04-13')],\n",
    "             '2020':[pd.to_datetime('2019-10-22')]}\n",
    "\n",
    "    df_temp = pd.DataFrame(pd.date_range(reg_dates['2016'][0], reg_dates['2020'][0], freq='D')).rename({0:'time'}, axis=1)\n",
    "    df_temp['doG'] = np.isin(df_temp.time, game_dates)\n",
    "    df_temp['doA'] = np.isin(df_temp.time, doA).astype(int)\n",
    "    df_temp['doR'] = np.isin(df_temp.time, doR).astype(int)\n",
    "    season_dates = pd.Series([item for sublist in list(reg_dates.values()) for item in sublist])\n",
    "    df_temp['season'] = np.isin(df_temp.time, season_dates)\n",
    "    df_temp['rest'] = np.isin(df_temp.time, pd.Series(rest_dates)).astype(int) \n",
    "    df_temp['absent'] = pd.Series(df_temp.doA + df_temp.season + df_temp['rest'] - df_temp.doR).replace({0, np.NaN})\n",
    "    df_temp['absent'] = df_temp['absent'].ffill().replace({1:0, -1:1})\n",
    "        \n",
    "    df_bask['player'] = player_name\n",
    "    df_bask['born'] = born\n",
    "    df_bask['absent'] = df_temp['absent']\n",
    "    df_bask['rest'] = rest_array\n",
    "\n",
    "    return df_bask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate data from all players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter & Explicitly Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset data to seasons before 2018-2019 and ignore all-stars who were traded in the middle the those seasons. Also define rest games from notes that explicitly use the word 'rest '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "omit_players = ['jimmy butler', 'andre drummond', 'carmelo anthony', 'dwanye wade', 'blake griffin', \n",
    "                'marc gasol', 'pau gasol', 'isaiah thomas', 'demarcus cousins', 'deandre jordan', 'dangelo russell']\n",
    "\n",
    "appended_data = []\n",
    "for player in pd.unique(stars.player):\n",
    "    if player not in omit_players:\n",
    "        df = get_data(player)\n",
    "        appended_data.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(appended_data, axis=0)\n",
    "df_all.to_csv(datadir + '/df_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is heavily biased, with only 50 observations of rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5608\n",
       "1      50\n",
       "Name: rest, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.rest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>elo_prob1</th>\n",
       "      <th>elo_prob2</th>\n",
       "      <th>b2b</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>df2.playoff_prob</th>\n",
       "      <th>miles</th>\n",
       "      <th>home</th>\n",
       "      <th>born</th>\n",
       "      <th>absent</th>\n",
       "      <th>rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "      <td>5658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017.956522</td>\n",
       "      <td>0.612881</td>\n",
       "      <td>0.387119</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>-0.398551</td>\n",
       "      <td>0.840232</td>\n",
       "      <td>583.116826</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1988.565217</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.008837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.398205</td>\n",
       "      <td>0.215160</td>\n",
       "      <td>0.215160</td>\n",
       "      <td>0.479425</td>\n",
       "      <td>82.693975</td>\n",
       "      <td>0.291460</td>\n",
       "      <td>586.875191</td>\n",
       "      <td>0.500044</td>\n",
       "      <td>3.281675</td>\n",
       "      <td>0.108183</td>\n",
       "      <td>0.093598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>0.064858</td>\n",
       "      <td>0.018315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1632.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>0.447325</td>\n",
       "      <td>0.204151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>0.642313</td>\n",
       "      <td>0.357687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>0.795849</td>\n",
       "      <td>0.552675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>0.981685</td>\n",
       "      <td>0.935142</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2708.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            season    elo_prob1    elo_prob2          b2b    days_rest  \\\n",
       "count  5658.000000  5658.000000  5658.000000  5658.000000  5658.000000   \n",
       "mean   2017.956522     0.612881     0.387119     0.357900    -0.398551   \n",
       "std       1.398205     0.215160     0.215160     0.479425    82.693975   \n",
       "min    2016.000000     0.064858     0.018315     0.000000 -1632.000000   \n",
       "25%    2017.000000     0.447325     0.204151     0.000000     2.000000   \n",
       "50%    2018.000000     0.642313     0.357687     0.000000     2.000000   \n",
       "75%    2019.000000     0.795849     0.552675     1.000000     2.000000   \n",
       "max    2020.000000     0.981685     0.935142     1.000000   197.000000   \n",
       "\n",
       "       df2.playoff_prob        miles         home         born       absent  \\\n",
       "count       5658.000000  5658.000000  5658.000000  5658.000000  5658.000000   \n",
       "mean           0.840232   583.116826     0.500000  1988.565217     0.011842   \n",
       "std            0.291460   586.875191     0.500044     3.281675     0.108183   \n",
       "min            0.000000     0.000000     0.000000  1979.000000     0.000000   \n",
       "25%            0.860000     0.000000     0.000000  1986.000000     0.000000   \n",
       "50%            0.990000   430.000000     0.500000  1989.000000     0.000000   \n",
       "75%            0.990000   937.000000     1.000000  1991.000000     0.000000   \n",
       "max            1.000000  2708.000000     1.000000  1994.000000     1.000000   \n",
       "\n",
       "              rest  \n",
       "count  5658.000000  \n",
       "mean      0.008837  \n",
       "std       0.093598  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Combining V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from glob import glob\n",
    "aneeshdir = '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/age_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/date_of_game_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/participated_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/team_playoff_probabilities_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/opponent_playoff_probabilities_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/opponent_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/time_elapsed_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/distance_traveled_layer.csv',\n",
       " '/Users/nickclifford/Documents/UVA/Spring 2020/SYS 6016 Machine Learning/final_proj/data/aneesh_data/home_game_layer.csv']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob(aneeshdir + '*')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the player names that are the column headers in each file\n",
    "col_names = ['John Wall', 'Khris Middleton', 'Nikola Vucevic',\n",
    "       'Devin Booker', 'Domantas Sabonis', 'Andre Drummond',\n",
    "       'LaMarcus Aldridge', 'Ben Simmons', 'Jimmy Butler', 'LeBron James',\n",
    "       'Dirk Nowitzki', 'Luka Doncic', 'Blake Griffin', 'Damian Lillard',\n",
    "       'Chris Paul', 'Jayson Tatum', 'Marc Gasol', 'Al Horford',\n",
    "       'Giannis Antetokounmpo', 'Bam Adebayo', 'Dwyane Wade', 'Brandon Ingram',\n",
    "       'Bradley Beal', 'Pau Gasol', 'Gordon Hayward', 'Karl-Anthony Towns',\n",
    "       'Paul George', 'Kevin Durant', 'Rudy Gobert', 'Goran Dragic',\n",
    "       'Kawhi Leonard', 'Kyrie Irving', 'Russell Westbrook', 'James Harden',\n",
    "       'Paul Millsap', 'Victor Oladipo', 'Isaiah Thomas', 'Draymond Green',\n",
    "       'Carmelo Anthony', 'Kemba Walker', 'Joel Embiid', 'Nikola Jokic',\n",
    "       'Donovan Mitchell', 'DeAndre Jordan', 'D\\'Angelo Russell',\n",
    "       'Pascal Siakam', 'DeMarcus Cousins', 'Kobe Bryant', 'Stephen Curry',\n",
    "       'Kyle Lowry', 'DeMar DeRozan', 'Trae Young', 'Anthony Davis',\n",
    "       'Klay Thompson']\n",
    "\n",
    "# Read in each file and melt from wide to long format\n",
    "long_dfs = []\n",
    "for file in file_list:\n",
    "    df_wide = pd.read_csv(file).rename({'Unnamed: 0':'game'}, axis=1)\n",
    "    value_name = file.split('/')[-1].rstrip('_layer.csv')\n",
    "    df_long = pd.melt(df_wide, id_vars='game', var_name='player', value_vars=col_names, value_name=value_name).set_index(['player', 'game'])\n",
    "    long_dfs.append(df_long)\n",
    "    \n",
    "\n",
    "df_all2 = reduce(lambda  left,right: pd.merge(left,right,on=['player', 'game'], how='outer'), long_dfs).reset_index()\n",
    "\n",
    "# rename columns\n",
    "df_all2 = df_all2.rename({'game':'game-season', 'ag':'age', 'date_of_gam':'date', 'participated':'rest', 'team_playoff_probabiliti':'df2.playoff_prob', \n",
    "                'opponent_playoff_probabiliti':'oppo_playoff_prob', 'time_elapsed':'days_rest', \n",
    "                          'distance_traveled':'miles', 'home_gam':'home'}, axis=1).reset_index()\n",
    "# add season and game fields\n",
    "df_all2['game'] = df_all2['game-season'].str.split().str[1]\n",
    "df_all2['season'] = df_all2['game-season'].str.split().str[-2]\n",
    "df_all2['date'] = pd.to_datetime(df_all2.date) # pd.datetime object\n",
    "df_all2['rest'] = df_all2.rest.replace({1:-1}).replace({0:1}).replace({-1:0}) # change rest day == 1, nonrest == 0\n",
    "df_all2['b2b'] = np.where(df_all2.date.diff() == pd.Timedelta('1 days 00:00:00'), 1, 0) # back to back col\n",
    "\n",
    "# rearrange columns\n",
    "df_all2 = df_all2[['player', 'date', 'season', 'game', 'opponent', 'age', \n",
    "                   'df2.playoff_prob', 'oppo_playoff_prob', 'days_rest', 'miles', 'home', 'b2b','rest']]\n",
    "\n",
    "df_all2 = df_all2[pd.notnull(df_all2['rest'])]\n",
    "#df_all2.to_csv(datadir + '/df_all2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>game</th>\n",
       "      <th>opponent</th>\n",
       "      <th>age</th>\n",
       "      <th>df2.playoff_prob</th>\n",
       "      <th>oppo_playoff_prob</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>miles</th>\n",
       "      <th>home</th>\n",
       "      <th>brb</th>\n",
       "      <th>rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>25.141684</td>\n",
       "      <td>66.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>2015-10-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>MIL</td>\n",
       "      <td>25.147159</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>NYK</td>\n",
       "      <td>25.149897</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>SAS</td>\n",
       "      <td>25.160849</td>\n",
       "      <td>68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>2015-11-06</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>BOS</td>\n",
       "      <td>25.166324</td>\n",
       "      <td>68.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>2020</td>\n",
       "      <td>59</td>\n",
       "      <td>UTA</td>\n",
       "      <td>29.754962</td>\n",
       "      <td>14.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21110</th>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>2020</td>\n",
       "      <td>60</td>\n",
       "      <td>LAL</td>\n",
       "      <td>29.760438</td>\n",
       "      <td>14.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21111</th>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>61</td>\n",
       "      <td>BOS</td>\n",
       "      <td>29.765914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21112</th>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>2020</td>\n",
       "      <td>62</td>\n",
       "      <td>NOP</td>\n",
       "      <td>29.771389</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21113</th>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>2020</td>\n",
       "      <td>63</td>\n",
       "      <td>MEM</td>\n",
       "      <td>29.776865</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19298 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              player       date season game opponent        age  \\\n",
       "0          John Wall 2015-10-28   2016    1      ORL  25.141684   \n",
       "1          John Wall 2015-10-30   2016    2      MIL  25.147159   \n",
       "2          John Wall 2015-10-31   2016    3      NYK  25.149897   \n",
       "3          John Wall 2015-11-04   2016    4      SAS  25.160849   \n",
       "4          John Wall 2015-11-06   2016    5      BOS  25.166324   \n",
       "...              ...        ...    ...  ...      ...        ...   \n",
       "21109  Klay Thompson 2019-11-11   2020   59      UTA  29.754962   \n",
       "21110  Klay Thompson 2019-11-13   2020   60      LAL  29.760438   \n",
       "21111  Klay Thompson 2019-11-15   2020   61      BOS  29.765914   \n",
       "21112  Klay Thompson 2019-11-17   2020   62      NOP  29.771389   \n",
       "21113  Klay Thompson 2019-11-19   2020   63      MEM  29.776865   \n",
       "\n",
       "       df2.playoff_prob  oppo_playoff_prob  days_rest   miles  home  brb  rest  \n",
       "0                  66.0               43.0       10.0   759.0   0.0    0   0.0  \n",
       "1                  66.0               34.0        2.0  1067.0   0.0    0   0.0  \n",
       "2                  66.0                6.0        1.0   635.0   1.0    1   0.0  \n",
       "3                  68.0               98.0        4.0     0.0   1.0    0   0.0  \n",
       "4                  68.0               84.0        2.0   394.0   0.0    0   0.0  \n",
       "...                 ...                ...        ...     ...   ...  ...   ...  \n",
       "21109              14.0               94.0        2.0  1379.0   1.0    0   1.0  \n",
       "21110              14.0               83.0        2.0   344.0   0.0    0   1.0  \n",
       "21111               3.0               99.9        2.0   344.0   1.0    0   1.0  \n",
       "21112               3.0               14.0        2.0  1917.0   0.0    0   1.0  \n",
       "21113               3.0                3.0        2.0   360.0   0.0    0   1.0  \n",
       "\n",
       "[19298 rows x 13 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data more loosely defines rest. Specifically, if players are inactive for short periods of time, or did not suffer from season-long inactivity, we label the games that they did not play as 'rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15663\n",
       "0.0     3635\n",
       "Name: rest, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all2.rest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>df2.playoff_prob</th>\n",
       "      <th>oppo_playoff_prob</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>miles</th>\n",
       "      <th>home</th>\n",
       "      <th>rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19298.000000</td>\n",
       "      <td>19298.000000</td>\n",
       "      <td>19298.000000</td>\n",
       "      <td>19298.000000</td>\n",
       "      <td>19298.000000</td>\n",
       "      <td>19298.000000</td>\n",
       "      <td>19298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.505228</td>\n",
       "      <td>67.569784</td>\n",
       "      <td>52.531812</td>\n",
       "      <td>2.213183</td>\n",
       "      <td>561.304177</td>\n",
       "      <td>0.499534</td>\n",
       "      <td>0.811639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.466052</td>\n",
       "      <td>37.976378</td>\n",
       "      <td>40.719080</td>\n",
       "      <td>1.297107</td>\n",
       "      <td>548.237036</td>\n",
       "      <td>0.500013</td>\n",
       "      <td>0.391011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.992471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.043806</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.370294</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.406571</td>\n",
       "      <td>99.900000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.807666</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2708.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  df2.playoff_prob  oppo_playoff_prob     days_rest  \\\n",
       "count  19298.000000      19298.000000       19298.000000  19298.000000   \n",
       "mean      27.505228         67.569784          52.531812      2.213183   \n",
       "std        4.466052         37.976378          40.719080      1.297107   \n",
       "min       18.992471          0.000000           0.000000      1.000000   \n",
       "25%       24.043806         34.000000           5.000000      2.000000   \n",
       "50%       27.370294         88.000000          58.000000      2.000000   \n",
       "75%       30.406571         99.900000          98.000000      2.000000   \n",
       "max       40.807666        100.000000         100.000000     10.000000   \n",
       "\n",
       "              miles          home          rest  \n",
       "count  19298.000000  19298.000000  19298.000000  \n",
       "mean     561.304177      0.499534      0.811639  \n",
       "std      548.237036      0.500013      0.391011  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      1.000000  \n",
       "50%      442.000000      0.000000      1.000000  \n",
       "75%      879.000000      1.000000      1.000000  \n",
       "max     2708.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all2.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
